{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "## Create a Fully Connected Minimal Neural Network for MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install necessary libraries\n",
    "#### If the libraries are not installed, please uncomment the code cell below and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WONT WORK WITH OLDER VERSIONS OF SCIKIT-LEARN\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "# mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit the scaler to the data and transform X\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = 10\n",
    "examples = y.shape[0]\n",
    "y = np.array([y]).reshape(1, examples)        #before doing y.reshape I change it to an array first. Finally y is an 1x70000 array. \n",
    "Y_new = np.eye(digits)[y.astype('int32')]       #1x70000x10\n",
    "Y_new = Y_new.T.reshape(digits, examples)       #10x70000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 70000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 70000),\n",
       " array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_new.shape,Y_new                          #one-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 60000                   #60000 for training\n",
    "m_test = X.shape[0] - m     #10000 for testing\n",
    "\n",
    "X_train, X_test = X[:m].T, X[m:].T\n",
    "Y_train, Y_test = Y_new[:,:m], Y_new[:,m:]\n",
    "\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]      #shuffled order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 60000), (784, 10000), (10, 60000), (10, 10000))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 12\n",
    "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "Y_train[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiclass_loss(Y, Y_hat):\n",
    "\n",
    "    m = Y.shape[1]\n",
    "    L = np.sum((Y_hat - Y) ** 2) / (m * Y.shape[0])\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the efficient loss function as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiclass_loss_efficient(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(-np.log(Y_hat) * Y)\n",
    "    m = Y.shape[1]\n",
    "    L = L_sum / m\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost:  11.036180613936944\n",
      "Epoch 100 cost:  0.771038256880198\n",
      "Epoch 200 cost:  0.5750471024698531\n",
      "Epoch 300 cost:  0.49326712083074303\n",
      "Epoch 400 cost:  0.4440121605163531\n",
      "Epoch 500 cost:  0.4094864873092847\n",
      "Epoch 600 cost:  0.38344511113168644\n",
      "Epoch 700 cost:  0.3629428672453237\n",
      "Epoch 800 cost:  0.3461496935319696\n",
      "Epoch 900 cost:  0.33197296328279646\n",
      "Epoch 1000 cost:  0.3197173574448934\n",
      "Epoch 1100 cost:  0.3089245010499718\n",
      "Epoch 1200 cost:  0.29928652377183246\n",
      "Epoch 1300 cost:  0.29058936467048546\n",
      "Epoch 1400 cost:  0.282676861965666\n",
      "Epoch 1500 cost:  0.2754303905130122\n",
      "Epoch 1600 cost:  0.268756355699893\n",
      "Epoch 1700 cost:  0.26257831945177357\n",
      "Epoch 1800 cost:  0.2568327845739807\n",
      "Epoch 1900 cost:  0.25146643737269314\n",
      "Final cost: 0.24648277307134137\n"
     ]
    }
   ],
   "source": [
    "n_x = X_train.shape[0]                #784 features\n",
    "n_h = 64                              #64 neurons \n",
    "learning_rate = 1\n",
    "\n",
    "W1 = np.random.randn(n_h, n_x)        #from input to hidden layer: a random matrix(64,784)\n",
    "b1 = np.zeros((n_h, 1))               #from input to hidden layer: a zero matrix(64,1)\n",
    "W2 = np.random.randn(digits, n_h)     #from the hidden layer to output: a random matrix(10,64)\n",
    "b2 = np.zeros((digits, 1))            #from the hidden layer to output: a zero matrix(10,1)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "\n",
    "for i in range(2000):\n",
    "\n",
    "    Z1 = np.matmul(W1,X)+b1         #sum: 64x784 X 784x60000 + 64x1\n",
    "    A1 = sigmoid(Z1)                   #sigmoid: 64x60000\n",
    "    Z2 = np.matmul(W2,A1)+b2           #sum: 10x64 X 64x60000 + 10x1\n",
    "    A2 = np.exp(Z2)/np.sum(np.exp(Z2), axis=0)    #softmax: 10x60000\n",
    "\n",
    "    cost = compute_multiclass_loss_efficient(Y, A2)\n",
    "\n",
    "    dZ2 = A2 - Y                        \n",
    "    dW2 = np.matmul((A2 - Y), A1.T)/m   \n",
    "    db2 = np.sum(A2 - Y, axis=1, keepdims=True)/m      \n",
    "\n",
    "    dA1 = np.matmul(W2.T, (A2 - Y))     \n",
    "    dZ1 = dA1*sigmoid(Z1)*(1-sigmoid(Z1))  \n",
    "    dW1 = np.matmul(dZ1,X.T)/m\n",
    "    db1 = np.sum(dZ1,axis=1, keepdims=True)/m\n",
    "\n",
    "    W2 = W2-dW2*learning_rate\n",
    "    b2 = b2-db2*learning_rate\n",
    "    W1 = W1-dW1*learning_rate\n",
    "    b1 = b1-db1*learning_rate\n",
    "\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Epoch\", i, \"cost: \", cost)\n",
    "\n",
    "print(\"Final cost:\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 948    0   11    3    1   17   17    3    9    6]\n",
      " [   0 1103    8    3    1    2    1    9    4    5]\n",
      " [   4    6  921   22    6    4    9   25    7    3]\n",
      " [   4    6   19  916    0   31    4    8   24    7]\n",
      " [   0    1   11    1  900    7   11    7   11   50]\n",
      " [  12    0    2   26    3  777   14    2   23    7]\n",
      " [   6    4   14    2   16   17  896    0   15    1]\n",
      " [   2    3   16   10    6    6    1  944    7   21]\n",
      " [   3   12   26   16    5   24    5    2  859   22]\n",
      " [   1    0    4   11   44    7    0   28   15  887]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2, A1) + b2\n",
    "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "predictions = np.argmax(A2, axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "\n",
    "print(confusion_matrix(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1015\n",
      "           1       0.97      0.97      0.97      1136\n",
      "           2       0.89      0.91      0.90      1007\n",
      "           3       0.91      0.90      0.90      1019\n",
      "           4       0.92      0.90      0.91       999\n",
      "           5       0.87      0.90      0.88       866\n",
      "           6       0.94      0.92      0.93       971\n",
      "           7       0.92      0.93      0.92      1016\n",
      "           8       0.88      0.88      0.88       974\n",
      "           9       0.88      0.89      0.88       997\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 92% Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Fangyi",
   "language": "python",
   "name": "ml-fangyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
